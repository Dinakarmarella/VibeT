

import os
os.environ['CURL_CA_BUNDLE'] = ''

import sys
import pandas as pd
import json
import requests

# Add the project root to the Python path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.find_similar_issues import IssueFinder
from sentence_transformers import SentenceTransformer

def generate_llm_analysis(new_issue, similar_issues_df, **kwargs):
    """
    Constructs a prompt ready to be used with a local or online LLM.
    """
    
    # --- 1. Augment: Construct the prompt ---
    prompt_context = ""
    for i, row in similar_issues_df.iterrows():
        prompt_context += f"- Historical Defect ID: {row['Defect_ID']}\n"
        prompt_context += f"  Summary: {row['Summary']}\n"
        prompt_context += f"  Resolved Root Cause: {row['Root_Cause']}\n\n"

    prompt = f"""You are an expert software engineering support analyst.

Analyze the following new issue based on the provided historical context from similar past defects.

**New Issue to Analyze:**
- Summary: {new_issue['Summary']}
- Comments: {new_issue['Comments']}
- Severity: {new_issue['Severity']}
- Application: {new_issue['Application']}

**Historical Context (Similar Past Defects):**
{prompt_context}
**Analysis Task:**
Based on the historical context, provide a detailed analysis of the new issue. Your analysis should include:
1.  A probable root cause for the new issue, with a brief justification referencing the historical data.
2.  A suggested resolution or a concrete next step for investigation.
"""

    print("\n--- Generated Prompt for LLM ---")
    print(prompt)
    print("-----------------------------")

    # --- 2. Return the prompt for manual use ---
    final_message = ("--- PROMPT FOR LLM ---\n\n" +
                   "The following prompt has been generated by the RAG pipeline. " +
                   "Copy and paste it into your preferred LLM (e.g., ChatGPT, Gemini) to get the analysis.\n\n" +
                   "------------------------------------------------------------------------------------\n\n" +
                   prompt)
    
    return final_message

def generate_rag_report(issue_details, output_file):
    """
    Generates a full RAG report by finding similar issues and using an LLM for analysis.
    """
    base_dir = os.path.dirname(__file__)
    index_file = os.path.join(base_dir, 'vector_index', 'diji_ai.index')
    mapping_file = os.path.join(base_dir, 'vector_index', 'data_mapping.pkl')

    if not os.path.exists(index_file):
        report_content = "Error: Vector index not found. Please run `src/build_vector_index.py` first."
        print(report_content)
    else:
        # Load the model once
        print("Loading sentence transformer model...")
        model = SentenceTransformer('all-MiniLM-L6-v2')

        # 1. Retrieve: Find similar issues
        finder = IssueFinder(index_file, mapping_file, model)
        query_text = issue_details['Summary'] + " " + issue_details['Comments']
        similar_issues = finder.find_similar(query_text, k=3)
        
        # 2. Augment & Generate: Get analysis from LLM
        report_content = generate_llm_analysis(issue_details, similar_issues)

    print("\n--- Final Report ---")
    print(report_content)
    print("--------------------")

    with open(output_file, 'w') as f:
        f.write(report_content)
    print(f"\nReport saved to {output_file}")

if __name__ == "__main__":
    # Example new issue for testing
    test_issue = {
        "Summary": "Inventory Service failing with error 503 and null references.",
        "Comments": "StackTrace>> NullRef @ line 79 in module_XYZ286. @@ Investigating Inventory Service ::: saw error==503 multiple times. !!! WARN !!! Users=affected >> count=38 sessions dropped. MonitorLogs== anomaly-pattern-[6649] !! see trace // ERROR $ AdditionalNote: !! config mismatch in env%$#path: /opt/app/bin/start.sh TemporaryFix>> restart service(Inventory Service) && clear-cache >> still failing.",
        "Severity": "high",
        "Application": "Inventory Service"
    }
    
    report_path = os.path.join(os.path.dirname(__file__), "prediction_report.txt")
    generate_rag_report(test_issue, output_file=report_path)
