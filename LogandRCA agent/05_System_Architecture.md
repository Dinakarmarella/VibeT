System Architecture Flow
Figure: High-level system architecture for the proposed LLM+KG log analysis system. The flow of data and queries is shown from log ingestion on the left to user interaction on the right. Key components include (A) ELK stack for collecting and indexing raw logs, (B) a triplet extraction module feeding structured events into the Knowledge Graph store, (C) integration of ITSM and other context data into the graph, (D) the LLM agent which interprets user queries and interacts with the graph, and (E) a user interface for analysts to query and receive summaries.
The architecture of the proposed system is composed of modular components working in a pipeline to enable end-to-end intelligent analysis of logs:
 Log Ingestion Layer (ELK Stack): Raw log data from various sources (application logs, system logs, network logs, etc.) is ingested through an ELK stack  typically using Logstash to parse and ingest, and Elasticsearch to store and index the logs. This layer handles high-volume streaming data and provides quick text-based searching as a fallback. Kibana or a similar dashboard could be used for basic visualization, but importantly, the logs are also forwarded to the next layer for semantic processing. The ingestion pipeline tags each log with metadata (source, timestamp, severity) and retains it in a time-series index.
 Triplet Extraction and Knowledge Graph Update: As logs flow in, an AI-driven parsing module analyzes each entry to extract structured information. This module may use NLP techniques (such as a smaller language model or regex patterns augmented with dictionaries) to find entities and relations in the log text. For example, from a log line WEB SERVER srv123 TIMEOUT connecting to DATABASE db45, it might extract a triplet like (, timeout connecting to , db45 ). These triples represent edges in the Knowledge Graph (KG). The KG is stored in a graph database (e.g., Neo4j or a similar graph DB) which can efficiently store nodes (entities like servers, services, IPs, error codes) and edges (relationships or events connecting those entities). In our KG, we also have node types for higher-level concepts: an Incident node (which might come from an ITSM ticket), or a Change node (from a deployment/change management system), etc. Plugins connect to external systems like the ITSM database to pull in these records and link them to log-derived nodes (e.g., linking an Incident node to a Server node if the incident is reported on that server). The result is a living knowledge graph that grows with each new log or relevant event, capturing the state of the environment and its history of interactions.
 LLM Query Processing and Reasoning Agent: The centerpiece is the LLM-based agent that interfaces with the user and the knowledge graph. This component includes a large language model (fine-tuned for IT operations, if necessary) and a controller that manages its interactions. When a user poses a question or when an automated alert query is triggered, the agent formulates a strategy to answer: it can translate the natural language query into one or multiple graph queries. For instance, if asked Summarize what happened to the payment service yesterday, the LLM might generate Cypher queries to retrieve all nodes and edges (log events, alerts, incidents) related to the payment service in the given time range. The results from the graph (and potentially from raw log index searches, if needed) are then fed back into the LLM. The LLM can interpret these results, perhaps ask for more information (iteratively refining the query), and ultimately compose a summary or explanation. This reasoning loop continues until the LLM agent is satisfied that it has enough information to answer the question. The agent employs chain-of-thought prompting internally, meaning it can break complex questions into sub-queries (e.g., find all errors preceding the crash, find config changes in that period, compare to last known similar incident). By unifying the process in one agent, the system avoids brittle, hardcoded logic  the LLM can flexibly decide how to search the graph or logs.
 User Interface and Feedback Loop: On the front-end, users interact with the system via a conversational interface (web or chat-based). They can ask questions in plain English (or other languages as supported by the LLM) and receive answers with cited evidence (e.g., references to specific log lines or graph entities). The interface visualizes relevant parts of the knowledge graph on demand  for example, showing a subgraph of services and error events when explaining a root cause. Importantly, the user can provide feedback. If the summary is not accurate, the user can correct it (Actually, that server was not the cause, it was the database  the logs show a DB failover.). The system records this feedback and can update the knowledge graph (marking certain nodes as root cause, or adding a link between an incident and the true culprit). Over time, this feedback is used to fine-tune the LLMs behavior (either via continual learning or adjusting its prompt/hint phrases). This learning loop means the system becomes smarter with each resolved incident, gradually accumulating a knowledge base of what solutions or explanations were valid.
 Security and Governance Layer: Underpinning the agents operation is a safety layer (as mentioned in the novelty section). All queries the LLM agent generates to the knowledge graph run through a sandbox. This layer ensures, for example, that the LLM doesnt accidentally expose sensitive information to a user without permission (it checks user access levels against data labels in the graph). It also prevents the agent from making destructive changes: the agent by default has readonly access to logs and knowledge graph, except through a controlled interface when updating the graph with confirmed information. Additionally, the system can rate-limit and monitor the LLMs queries to avoid any infinite loops or runaway costs (since large models can be resource-intensive). If the agents reasoning seems to go awry (e.g., stuck in a loop or producing irrelevant results), a watchdog process can intervene or reset the session. This governance layer ensures the solution can be trusted in a production environment.
In summary, the architecture marries data pipeline components (for ingestion and knowledge storage) with AI components (LLM agent for reasoning, NLP for extraction) and wraps them in a user-centric interface with proper controls. This design allows free-flowing analysis: a users natural question propagates through the system, pulls together the right evidence from a variety of sources, and comes back as a coherent answer  much like asking a knowledgeable colleague who has read all the logs and remembers all past incidents.